# -*- coding: utf-8 -*-
"""regreção.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Antonioarf/blox/blob/master/estudo_programa.ipynb
"""

# encoding: utf-8
# encoding: iso-8859-1
# encoding: win-1252


# !pip install stop_words
# %matplotlib inline
# df1.to_excel(r'C:\Users\Antonio Fonseca\Desktop\BLOX\ementas.xlsx')
# n esquecer do tensorflow

#from nltk.corpus import stopwords
#import nltk
#import numpy as np
#import matplotlib.pyplot as plt
#from sklearn.model_selection import train_test_split
#from sklearn.utils import shuffle
#from scipy.stats import expon, binom, t, norm, probplot, scoreatpercentile, percentileofscore
#import seaborn as sns # evite fazer pairplot! Estoura a memória
#import statsmodels.api as sm 
#from sklearn.naive_bayes import MultinomialNB
#from sklearn.feature_extraction.text import CountVectorizer
#from nltk.tokenize import word_tokenize
#from nltk import pos_tag
#from nltk.corpus import stopwords
#from nltk.stem import WordNetLemmatizer
#from sklearn.preprocessing import LabelEncoder
#from collections import defaultdict
#from nltk.corpus import wordnet as wn
#from sklearn.feature_extraction.text import TfidfVectorizer
#from sklearn import model_selection, naive_bayes, svm
#from sklearn.metrics import accuracy_score
#from sklearn import svm

import pandas as pd;
from stop_words import get_stop_words
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer

import gspread
from oauth2client.service_account import ServiceAccountCredentials

scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
creds = ServiceAccountCredentials.from_json_keyfile_name("ml-blox.json",scope)
client= gspread.authorize(creds)
sheet = client.open("Cópia de NOVO CINE de ESPM - Pós - Matriz de Referência").sheet1

data = sheet
#headers = sheet.row_values(1)
#print (headers), columns = headers
espm = pd.DataFrame(data)
with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also
    print(espm)

# treino = pd.read_csv('treino.csv')  
url = 'https://github.com/Antonioarf/blox/blob/master/excel/Book1.xlsx?raw=true'
df1 = pd.read_excel(url)
df1 = df1.loc[:, ~df1.columns.str.contains('^Unnamed')]
treino = df1.dropna()


def deletar_caracteres(coluna):
# coluna = coluna.replace("Humanidades e Linguagens","Humanidades, Artes e Linguagens").replace("Matemática e Computação","Matemática, Computação e Tecnologias de Informação e Comunicacão").replace("Ciências Sociais e Negócios","Ciências Sociais, Jornalismo e Informação").replace("Psicologia e Desenvolvimento","Psicologia e Desenvolvimento Pessoal").replace("Negócios e Administração","Administração e Negócios")
# coluna = coluna.replace("Ciências Sociais, Jornalismo e Informação",'1').replace("Saúde e Bem-Estar Social",'2').replace("Engenharia, Produção e Construção",'3').replace("Ciências Naturais",'4').replace('Humanidades, Artes e Linguagens','5').replace("Matemática, Computação e Tecnologias de Informação e Comunicacão",'6').replace("Direito",'7').replace("Educação",'8').replace("Psicologia e Desenvolvimento Pessoal",'9').replace("Serviços",'10').replace("Administração e Negócios",'11')
    
    return coluna


stop = get_stop_words('pt')

my_tags = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14']
# my_tags =[1,2,3,4,5,6,7,8,9,10,11]







# Commented out IPython magic to ensure Python compatibility.
print("escreva o nome do arquivo com complemento (e caminho, se não estiver na mesma pasta)")
#excel = input (str())
print ("QUal o nome da coluna com as materias?")
#coluna = input(str())
def machine (planilha,coluna):
  X_train =  treino["materias"]
  y_train = deletar_caracteres(treino["ÁREA DO CONHECIMENTO"])
  X_test = panilha[coluna]
  logreg = Pipeline([('vect', TfidfVectorizer(stop_words= stop)),
                ('tfidf', TfidfTransformer()),
                ('clf', LogisticRegression(n_jobs=1, C=1e5)),
               ])
  logreg.fit(X_train, y_train)

#   %time

  y_pred = logreg.predict(X_test)

  # print('accuracy %s' % accuracy_score(y_pred, y_test))
  # print(classification_report(y_test, y_pred))
  return y_pred







## Commented out IPython magic to ensure Python compatibility.
#from sklearn.linear_model import LogisticRegression
#from sklearn.metrics import classification_report
#
#logreg = Pipeline([('vect', TfidfVectorizer(stop_words= stop)),
#                ('tfidf', TfidfTransformer()),
#                ('clf', LogisticRegression(n_jobs=1, C=1e5)),
#               ])
#logreg.fit(X_train, y_train)
#
## %time
#
#y_pred = logreg.predict(X_test)
#
#print('accuracy %s' % accuracy_score(y_pred, y_test))
#print(classification_report(y_test, y_pred))
